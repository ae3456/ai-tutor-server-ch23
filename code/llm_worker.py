# 23.x èŠ‚ä»£ç ï¼šllm_worker.py
import pika
import json
import time
import os
import struct
import requests
from langchain_openai import ChatOpenAI
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import base64
import logging

# å¤©æ°”æŸ¥è¯¢ç›¸å…³é…ç½®ï¼ˆå¿…é¡»ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œä¸è¦ç¡¬ç¼–ç ï¼‰
WEATHER_ENDPOINT = os.getenv("WEATHER_ENDPOINT", "")
WEATHER_CITY = os.getenv("WEATHER_CITY", "åŒ—äº¬")
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'
)
logger = logging.getLogger("LLM_Worker")
from aip import AipSpeech # å¯¼å…¥ç™¾åº¦è¯­éŸ³ API SDK
# --- 1. é…ç½®ä¸ AI æ ¸å¿ƒåˆå§‹åŒ– ---
llm = ChatOpenAI(
    base_url=os.getenv("LLM_BASE_URL"),
    api_key=os.getenv("LLM_API_KEY"),
    model="doubao-1-5-lite-32k-250115", # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯·æ›¿æ¢ä¸ºä½ å®é™…ä½¿ç”¨çš„æ¨¡å‹
    temperature=0.7
)
REDIS_HOST = os.getenv('REDIS_HOST', 'redis')
REDIS_URL = f"redis://{REDIS_HOST}:6379/0"

# é”™è¯¯æ¶ˆæ¯å¸¸é‡
ERROR_MESSAGES = {
    "asr_failed": "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•",
    "tts_failed": "è¯­éŸ³åˆæˆå¤±è´¥ï¼Œè¯·é‡è¯•",
    "llm_failed": "AIå¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•",
    "timeout": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•",
    "unknown": "ç³»ç»Ÿé”™è¯¯ï¼Œè¯·é‡è¯•"
}

# å°æ™º AI åŠ©æ‰‹ Prompt
template = """
ä½ æ˜¯ä¸€ä¸ªåå«å°æ™ºçš„å‹å¥½ã€è€å¿ƒä¸”èªæ˜çš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€‚
å½“å‰å¯¹è¯å†å²: {chat_history}
ç”¨æˆ·: {question}
å°æ™º:
"""
prompt = PromptTemplate(input_variables=["chat_history", "question"], template=template)

def get_weather_by_responses_api(city=None) -> str:
    """
    ä½¿ç”¨ç«å±±æ–¹èˆŸ Responses API è”ç½‘æœç´¢å¤©æ°”
    åˆ©ç”¨è±†åŒ…å¤§æ¨¡å‹çš„è”ç½‘æœç´¢èƒ½åŠ›è·å–å®æ—¶å¤©æ°”
    """
    if not city:
        city = WEATHER_CITY
    
    api_key = os.getenv("LLM_API_KEY", "")
    endpoint_id = WEATHER_ENDPOINT
    
    if not api_key:
        logger.error("æœªé…ç½®LLM_API_KEYï¼Œæ— æ³•æŸ¥è¯¢å¤©æ°”")
        return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©é€‚å®œï¼Œç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼"
    
    if not endpoint_id:
        logger.error("æœªé…ç½®WEATHER_ENDPOINTï¼Œæ— æ³•æŸ¥è¯¢å¤©æ°”")
        return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©é€‚å®œï¼Œç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼"
    
    try:
        url = "https://ark.cn-beijing.volces.com/api/v3/responses"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": endpoint_id,
            "stream": False,
            "tools": [
                {"type": "web_search"}  # å¼€å¯è”ç½‘æœç´¢
            ],
            "input": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "text",
                            "text": "ä½ æ˜¯å¤©æ°”æ’­æŠ¥åŠ©æ‰‹ã€‚è¯·ç®€æ´æ’­æŠ¥å¤©æ°”ï¼Œ50å­—ä»¥å†…ï¼Œå¿…é¡»åŒ…å«é—®å€™è¯­ï¼Œè¯­æ°”äº²åˆ‡è‡ªç„¶ã€‚"
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"è¯·æœç´¢{city}ä»Šå¤©çš„å®æ—¶å¤©æ°”ï¼Œå‘Šè¯‰æˆ‘æ¸©åº¦ã€å¤©æ°”çŠ¶å†µå’Œç®€å•çš„ç©¿è¡£å»ºè®®ã€‚"
                        }
                    ]
                }
            ]
        }
        
        logger.info(f"è°ƒç”¨Responses APIæŸ¥è¯¢{city}å¤©æ°”...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        
        # è§£æResponses APIè¿”å›æ ¼å¼
        if result and "output" in result:
            output_list = result["output"]
            if isinstance(output_list, list) and len(output_list) > 0:
                # æ‰¾åˆ°assistantçš„æœ€åä¸€æ¡æ¶ˆæ¯
                for item in reversed(output_list):
                    if item.get("role") == "assistant":
                        content = item.get("content", [])
                        if isinstance(content, list) and len(content) > 0:
                            weather_text = content[0].get("text", "").strip()
                        else:
                            weather_text = str(content).strip()
                        
                        # ç¡®ä¿æœ‰é—®å€™è¯­
                        if weather_text and not weather_text.startswith(("æ‚¨å¥½", "ä½ å¥½", "å¤§å®¶å¥½")):
                            weather_text = f"æ‚¨å¥½ï¼Œ{weather_text}"
                        
                        logger.info(f"å¤©æ°”æŸ¥è¯¢æˆåŠŸ: {weather_text[:60]}...")
                        return weather_text if weather_text else f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”ä¸é”™ã€‚"
            
            logger.warning(f"APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œå°è¯•ç›´æ¥è§£æ: {result}")
            return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©é€‚å®œã€‚"
        else:
            logger.error(f"APIè¿”å›ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {result}")
            return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚"
            
    except requests.exceptions.Timeout:
        logger.error("å¤©æ°”APIè¯·æ±‚è¶…æ—¶")
        return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©é€‚å®œã€‚"
    except requests.exceptions.RequestException as e:
        logger.error(f"è¯·æ±‚å¤©æ°”APIå¤±è´¥: {e}")
        return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼"
    except Exception as e:
        logger.error(f"å¤©æ°”æŸ¥è¯¢å¼‚å¸¸: {e}")
        return f"æ‚¨å¥½ï¼Œ{city}ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚"

def get_weather_response(city=None) -> str:
    """
    è·å–å¤©æ°”æ’­æŠ¥æ–‡æœ¬ï¼ˆä½¿ç”¨è±†åŒ…è”ç½‘æœç´¢ï¼‰
    """
    return get_weather_by_responses_api(city)
# --- è¯­éŸ³ API å®¢æˆ·ç«¯åˆå§‹åŒ– ---
APP_ID = os.getenv("BAIDU_VOICE_APP_ID")
API_KEY = os.getenv("BAIDU_VOICE_API_KEY")
SECRET_KEY = os.getenv("BAIDU_VOICE_SECRET_KEY")
# åˆå§‹åŒ–ç™¾åº¦è¯­éŸ³ API å®¢æˆ·ç«¯
try:
    speech_client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)
except Exception as e:
    print(f"Warning: Baidu AipSpeech Client initialization failed. Check environment variables. Error: {e}")

# PCMè½¬WAVå‡½æ•°
def pcm_to_wav(pcm_data: bytes, sample_rate=16000, channels=1, bits_per_sample=16) -> bytes:
    """
    å°†åŸå§‹PCMæ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼
    """
    # WAVå¤´éƒ¨ç»“æ„
    byte_rate = sample_rate * channels * bits_per_sample // 8
    block_align = channels * bits_per_sample // 8
    data_size = len(pcm_data)

    wav_header = struct.pack(
        '<4sI4s4sIHHIIHH4sI',
        b'RIFF',
        36 + data_size,
        b'WAVE',
        b'fmt ',
        16,  # fmt chunk size
        1,   # audio format (PCM)
        channels,
        sample_rate,
        byte_rate,
        block_align,
        bits_per_sample,
        b'data',
        data_size
    )
    return wav_header + pcm_data

# æ¨¡æ‹Ÿ ASR å‡½æ•° (æ¥è‡ª 15.2 èŠ‚)
def transcribe_audio_stream(audio_bytes: bytes) -> str:
    """
    æ¥æ”¶éŸ³é¢‘äºŒè¿›åˆ¶æµï¼Œè°ƒç”¨ç™¾åº¦ STT (ASR) API è¿›è¡Œè½¬å½•ã€‚
    æ³¨æ„ï¼šè¾“å…¥ä¸ºåŸå§‹PCMæ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸ºWAVæ ¼å¼
    """
    if speech_client is None:
        logger.error("ç™¾åº¦è¯­éŸ³å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        return ""

    try:
        # å°†åŸå§‹PCMæ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼
        wav_data = pcm_to_wav(audio_bytes, sample_rate=16000, channels=1, bits_per_sample=16)
        logger.debug(f"PCMè½¬WAVå®Œæˆ: è¾“å…¥ {len(audio_bytes)} å­—èŠ‚, è¾“å‡º {len(wav_data)} å­—èŠ‚")
    except Exception as e:
        logger.error(f"PCMè½¬WAVå¤±è´¥: {e}")
        return ""

    # dev_pid=1536 æ˜¯ç™¾åº¦è¯­éŸ³è¯†åˆ«çš„æ™®é€šè¯è¯†åˆ«æ¨¡å‹ ID
    stt_result = speech_client.asr(wav_data, 'wav', 16000, {'dev_pid': 1536})

    if stt_result and stt_result.get('err_no') == 0 and stt_result.get('result'):
        # è¿”å›è½¬å½•ç»“æœä¸­çš„ç¬¬ä¸€ä¸ªå¥å­
        return stt_result['result'][0]
    else:
        # å¦‚æœ ASR å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸²æˆ–é”™è¯¯ä¿¡æ¯
        logger.error(f"STT (ASR) é”™è¯¯: {stt_result}")
        return ""
def get_ai_response_with_redis(user_input: str, user_id: str) -> str:
    """åŒæ­¥å‡½æ•°ï¼šä» Redis åŠ è½½è®°å¿†ï¼Œè°ƒç”¨ LLMï¼Œå°†æ–°ç»“æœå­˜å› Redisã€‚"""
    # ç§»é™¤æ¨¡æ‹Ÿå»¶è¿Ÿï¼ŒçœŸå®LLMè°ƒç”¨å·²æœ‰å¤„ç†æ—¶é—´ 
    
    history = RedisChatMessageHistory(session_id=user_id, url=REDIS_URL)
    memory = ConversationBufferMemory(memory_key="chat_history", chat_memory=history)
    tutor_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
    
    # è°ƒç”¨ LLMï¼Œå¹¶è®© Memory è‡ªåŠ¨æ›´æ–° Redis
    response_text = tutor_chain.predict(question=user_input)
    return response_text


# --- 2. æ¶ˆæ¯å¤„ç†å›è°ƒå‡½æ•° (Consumer/Producer çš„æ ¸å¿ƒ) ---
def callback(ch, method, properties, body):
    """å½“ Worker Service ä» llm_request_queue æ¥æ”¶åˆ°æ¶ˆæ¯æ—¶è¢«è°ƒç”¨ã€‚"""
    try:
        task_data = json.loads(body)
        user_id = task_data['user_id']  
        task_id = task_data['task_id']         
        audio_b64 = task_data.get('audio_data_base64', '')
        is_weather_report = task_data.get('is_weather_report', False)
        
        logger.info(f"[{user_id}][{task_id}] LLM Worker æ”¶åˆ°ä»»åŠ¡ã€‚å¤©æ°”æ’­æŠ¥: {is_weather_report}")
        
        # ========== å¤©æ°”æ’­æŠ¥ä»»åŠ¡å¤„ç† ==========
        if is_weather_report:
            logger.info(f"[{user_id}][{task_id}] ğŸŒ¤ï¸ å¤„ç†å¤©æ°”æ’­æŠ¥ä»»åŠ¡")
            
            # è·å–å¤©æ°”æ’­æŠ¥æ–‡æœ¬ï¼ˆè°ƒç”¨å¤©æ°”API + LLMç”Ÿæˆï¼‰
            ai_response_text = get_weather_response()
            
            logger.info(f"[{user_id}][{task_id}] å¤©æ°”æ’­æŠ¥å†…å®¹: {ai_response_text}")
            
            # å‘é€åˆ° TTS é˜Ÿåˆ—
            tts_task_message = {             
                "task_id": task_id,             
                "user_id": user_id,             
                "ai_response_text": ai_response_text,
                "is_weather_report": True
            }
            
            ch.basic_publish(             
                exchange='',             
                routing_key='tts_request_queue',
                body=json.dumps(tts_task_message),             
                properties=pika.BasicProperties(                 
                    delivery_mode=pika.DeliveryMode.Persistent             
                )         
            )
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            logger.info(f"[{user_id}][{task_id}] å¤©æ°”æ’­æŠ¥ä»»åŠ¡å·²å‘é€åˆ° tts_request_queue")
            return
        
        # ========== æ­£å¸¸å¯¹è¯ä»»åŠ¡å¤„ç† ==========
        if not audio_b64:
            logger.error(f"[{user_id}][{task_id}] éŸ³é¢‘æ•°æ®ä¸ºç©º")
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return
        
        # 1. Base64 è§£ç 
        audio_bytes = base64.b64decode(audio_b64)
        
        # 2. è°ƒç”¨ ASR è¯­éŸ³è¯†åˆ«
        user_text = transcribe_audio_stream(audio_bytes)
        if not user_text:
            logger.error(f"[{user_id}][{task_id}] ASR è¯†åˆ«å¤±è´¥")
            error_message = {
                "user_id": user_id,
                "event": "error",
                "type": "asr_failed",
                "message": ERROR_MESSAGES["asr_failed"]
            }
            ch.basic_publish(
                exchange='',
                routing_key='websocket_response_queue',
                body=json.dumps(error_message),
                properties=pika.BasicProperties(
                    delivery_mode=pika.DeliveryMode.Persistent
                )
            )
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return
        
        logger.info(f"[{user_id}][{task_id}] ASR ç»“æœ: {user_text}")          
        
        # 3. è°ƒç”¨ LLM æ ¸å¿ƒ
        ai_response_text = get_ai_response_with_redis(user_text, user_id)                  
        logger.info(f"[{user_id}][{task_id}] LLM å¤„ç†å®Œæ¯•ã€‚å‡†å¤‡å‘é€åˆ° TTS é˜Ÿåˆ—...")                  
        # 4. ã€ä¿®æ”¹ã€‘æ„å»ºå‘é€ç»™ TTS Worker çš„æ–°æ¶ˆæ¯         
        tts_task_message = {             
            "task_id": task_id,             
            "user_id": user_id,             
            "ai_response_text": ai_response_text # å°† AI å›å¤æ–‡æœ¬ä¼ é€’ä¸‹å»         
        }                
        # 5. ã€ä¿®æ”¹ã€‘å°†ä»»åŠ¡å‘å¸ƒåˆ° 'tts_request_queue'         
        ch.basic_publish(             
            exchange='',             
            routing_key='tts_request_queue', # å‘é€åˆ° TTS é˜Ÿåˆ—             
            body=json.dumps(tts_task_message),             
            properties=pika.BasicProperties(                 
                delivery_mode=pika.DeliveryMode.Persistent             
            )         
        )          
        # 6. ç¡®è®¤æ¶ˆæ¯å¤„ç†å®Œæˆ (ACK)         
        ch.basic_ack(delivery_tag=method.delivery_tag)         
        logger.info(f"[{user_id}][{task_id}] ä»»åŠ¡å·²æˆåŠŸå‘é€åˆ° tts_request_queueã€‚")      
    except Exception as e:
        logger.error(f"å¤„ç† LLM ä»»åŠ¡æ—¶å‡ºé”™: {e}")
        # å°è¯•ä»bodyä¸­è§£æuser_idï¼Œå¦‚æœè§£æå¤±è´¥åˆ™ä½¿ç”¨æœªçŸ¥ID
        user_id = "unknown"
        try:
            task_data = json.loads(body)
            user_id = task_data.get('user_id', 'unknown')
        except:
            pass

        # å‘é€é”™è¯¯æ¶ˆæ¯åˆ° websocket_response_queue
        error_message = {
            "user_id": user_id,
            "event": "error",
            "type": "llm_failed",
            "message": ERROR_MESSAGES["llm_failed"]
        }
        try:
            ch.basic_publish(
                exchange='',
                routing_key='websocket_response_queue',
                body=json.dumps(error_message),
                properties=pika.BasicProperties(
                    delivery_mode=pika.DeliveryMode.Persistent
                )
            )
            # ç¡®è®¤æ¶ˆæ¯ï¼Œé¿å…é‡å¤å¤„ç†
            ch.basic_ack(delivery_tag=method.delivery_tag)
        except Exception as inner_e:
            logger.error(f"å‘é€é”™è¯¯æ¶ˆæ¯å¤±è´¥: {inner_e}")
            # å¦‚æœå‘é€å¤±è´¥ï¼ŒNACKæ¶ˆæ¯
            ch.basic_nack(delivery_tag=method.delivery_tag)


# --- 3. ä¸»ç¨‹åºå…¥å£ (å¯åŠ¨ Consumer) ---
if __name__ == '__main__':
    logger.info('LLM Worker Service: Starting up...')
    
    MQ_HOST = os.getenv("RABBITMQ_HOST", "localhost")

    connection = pika.BlockingConnection(pika.ConnectionParameters(MQ_HOST))
    channel = connection.channel()
    
    channel.queue_declare(queue='llm_request_queue', durable=True)
    channel.queue_declare(queue='tts_request_queue', durable=True)
    
    # è®¾ç½® QoS (Quality of Service)ï¼šä¸€æ¬¡åªç»™è¿™ä¸ª Worker å‘é€ä¸€ä¸ªæ¶ˆæ¯
    channel.basic_qos(prefetch_count=1) 
    
    # å¯åŠ¨æ¶ˆè´¹è€…
    channel.basic_consume(queue='llm_request_queue', on_message_callback=callback)
    
    logger.info(' [*] Waiting for messages. To exit press CTRL+C')
    channel.start_consuming()